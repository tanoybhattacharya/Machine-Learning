{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paribas_data = pd.read_csv('train.csv', nrows=20000)  \n",
    "paribas_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colums = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']  \n",
    "numerical_columns = list(paribas_data.select_dtypes(include=num_colums).columns)  \n",
    "paribas_data = paribas_data[numerical_columns]  \n",
    "paribas_data.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(  \n",
    "    paribas_data.drop(labels=['target', 'ID'], axis=1),\n",
    "    paribas_data['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()  \n",
    "correlation_matrix = paribas_data.corr()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(correlation_matrix .columns)):  \n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "\n",
    "train_features.drop(labels=correlated_features, axis=1, inplace=True)  \n",
    "test_features.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection ##\n",
    "\n",
    "### Wrapper###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __k_features__ specifies the number of features to select. You can set any number of features here. The __forward__ parameter, if set to True, performs step forward feature selection. The __verbose__ parameter is used for logging the progress of the feature selector, the __scoring__ (https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)parameter defines the performance evaluation criteria and finally, __cv__ refers to cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Step Forward Feature Selection in Python\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),  \n",
    "           k_features=15,\n",
    "           forward=True, # for backward feature Selection set as False\n",
    "           verbose=2,\n",
    "           scoring='roc_auc',\n",
    "           cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_selector.fit(np.array(train_features.fillna(0)), train_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_features= train_features.columns[list(features.k_feature_idx_)]  \n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=41, max_depth=3)  \n",
    "model = clf.fit(train_features[filtered_features].fillna(0), train_labels)\n",
    "\n",
    "train_pred = clf.predict_proba(train_features[filtered_features].fillna(0))  \n",
    "print('Accuracy on training set: {}'.format(roc_auc_score(train_labels, train_pred[:,1])))\n",
    "\n",
    "test_pred = clf.predict_proba(test_features[filtered_features].fillna(0))  \n",
    "print('Accuracy on test set: {}'.format(roc_auc_score(test_labels, test_pred [:,1])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class has __min_features__ and __max_features__ attributes which can be used to specify the minimum and the maximum number of features in the combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = ExhaustiveFeatureSelector(RandomForestClassifier(n_jobs=-1),  \n",
    "           min_features=2,\n",
    "           max_features=4,\n",
    "           scoring='roc_auc',\n",
    "           print_progress=True,\n",
    "           cv=2)\n",
    "features = feature_selector.fit(np.array(train_features.fillna(0)), train_labels)  \n",
    "\n",
    "filtered_features= train_features.columns[list(features.k_feature_idx_)]  \n",
    "\n",
    "clf_Exf = RandomForestClassifier(n_estimators=100, random_state=41, max_depth=3)  \n",
    "clf_Exf.fit(train_features[filtered_features].fillna(0), train_labels)\n",
    "\n",
    "train_pred = clf_Exf.predict_proba(train_features[filtered_features].fillna(0))  \n",
    "print('Accuracy on training set: {}'.format(roc_auc_score(train_labels, train_pred[:,1])))\n",
    "\n",
    "test_pred = clf_Exf.predict_proba(test_features[filtered_features].fillna(0))  \n",
    "print('Accuracy on test set: {}'.format(roc_auc_score(test_labels, test_pred [:,1])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict_proba(test[filtered_features].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict[:,0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(Y_predict, (1,len(Y_predict)*2))\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ 'ID': test['ID'],\n",
    "                            'PredictedProb': Y_predict[:,1]  })\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ 'ID': test['ID'],\n",
    "                            'PredictedProb': Y_predict[:,0]  })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
